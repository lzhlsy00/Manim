# Manimations API

An API-based educational animation generator using Manim and Claude AI. This service accepts natural language prompts and generates educational animation videos automatically with optional AI-generated narration.

## ğŸš€ Features

- ğŸ¬ Generate educational animations from text prompts
- ğŸ¤– Powered by Claude AI for intelligent script generation
- ğŸ§® Built with Manim for high-quality mathematical animations
- ğŸš€ FastAPI-based REST API
- ğŸ¥ Multiple resolution support (480p to 1080p)
- ğŸ”Š AI-generated narration with multiple voices and languages
- ğŸ¯ Audio-video synchronization with timing analysis
- ğŸŒ **æ™ºèƒ½è¯­è¨€æ£€æµ‹å’Œè¯­éŸ³åŒ¹é…**: è‡ªåŠ¨æ£€æµ‹è¾“å…¥è¯­è¨€ï¼Œå¹¶ä¸ºæ¯ç§è¯­è¨€é€‰æ‹©æœ€é€‚åˆçš„TTSè¯­éŸ³
- ğŸ—£ï¸ **å¤šè¯­è¨€TTSæ”¯æŒ**: æ”¯æŒ12ç§è¯­è¨€ï¼Œæ¯ç§è¯­è¨€éƒ½æœ‰ä¸“é—¨ä¼˜åŒ–çš„è¯­éŸ³é€‰æ‹©
- ğŸ“± Direct video URL access for easy embedding

## ğŸ“‹ Prerequisites

- **Python 3.13+**
- **FFmpeg** (required for audio/video processing)
- **LaTeX distribution** (for mathematical formulas)
- **Anthropic API Key** (for Claude AI)
- **OpenAI API Key** (optional, for narration)

## ğŸ› ï¸ Installation

### 1. Clone the repository
```bash
git clone <repository-url>
cd manimations
```

### 2. Install uv (Python package manager)
```bash
# Install uv (recommended by Manim)
curl -LsSf https://astral.sh/uv/install.sh | sh
source $HOME/.cargo/env
```

### 3. Install dependencies
```bash
uv sync
```

### 4. Install system dependencies

**macOS:**
```bash
brew install ffmpeg
brew install --cask mactex
```

**Ubuntu/Debian:**
```bash
sudo apt update
sudo apt install ffmpeg texlive-full
```

**Windows:**
- Download FFmpeg from https://ffmpeg.org/download.html
- Install MiKTeX from https://miktex.org/

### 5. Set environment variables

Create a `.env` file from the template:
```bash
cp .env.example .env
# Edit .env with your API keys
```

Or set environment variables manually:
```bash
export ANTHROPIC_API_KEY="your-anthropic-api-key"
export OPENAI_API_KEY="your-openai-api-key"  # Optional, for narration
```

## ğŸš€ Running the API

### Start the server
```bash
# Development mode (with auto-reload)
uv run uvicorn app:app --host 0.0.0.0 --port 8000 --reload

# Production mode (multiple workers)
uv run uvicorn app:app --host 0.0.0.0 --port 8000 --workers 4
```

The API will be available at `http://localhost:8000`

Visit `http://localhost:8000/docs` for interactive API documentation.

## ğŸ“š API Endpoints

### `GET /` - Root Information
Returns basic API information and available endpoints.

**Response:**
```json
{
  "message": "Manimations API - Educational Animation Generator",
  "endpoints": {
    "generate": "/generate - POST request with prompt",
    "health": "/health - Check API health"
  }
}
```

### `GET /health` - Health Check
Simple health check endpoint.

**Response:**
```json
{
  "status": "healthy",
  "service": "manimations-api"
}
```

### `POST /generate` - Generate Animation
Generate an educational animation video from a text prompt.

**Request Body:**
```json
{
  "prompt": "Explain the Pythagorean theorem with a visual proof",
  "resolution": "m",
  "include_audio": true,
  "voice": "alloy",
  "language": "en",
  "sync_method": "timing_analysis"
}
```

**Parameters:**
- `prompt` (string, required): Natural language description of the animation
- `resolution` (string, optional): Video quality
  - `"l"` - Low quality (480p)
  - `"m"` - Medium quality (720p, default)
  - `"h"` - High quality (1080p)
  - `"p"` - Production quality
  - `"k"` - 4K quality
- `include_audio` (boolean, optional): Whether to generate narration (default: true)
- `voice` (string, optional): TTS voice for narration
  - `"alloy"` (default), `"echo"`, `"fable"`, `"onyx"`, `"nova"`, `"shimmer"`
  - **æ™ºèƒ½è¯­éŸ³é€‰æ‹©**: å¦‚æœä½¿ç”¨é»˜è®¤è¯­éŸ³ `"alloy"`ï¼Œç³»ç»Ÿä¼šæ ¹æ®æ£€æµ‹åˆ°çš„è¯­è¨€è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„è¯­éŸ³
- `language` (string, optional): Language code (auto-detected if not specified)
  - Supported: `en`, `es`, `fr`, `de`, `it`, `pt`, `ru`, `ja`, `ko`, `zh`, `ar`, `hi`
  - **è‡ªåŠ¨è¯­éŸ³æ˜ å°„**: ç³»ç»Ÿä¼šæ ¹æ®è¯­è¨€è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„TTSè¯­éŸ³ï¼š
    - ğŸ‡ºğŸ‡¸ è‹±è¯­ (en) â†’ alloy (æ¸…æ™°ä¸­æ€§)
    - ğŸ‡ªğŸ‡¸ è¥¿ç­ç‰™è¯­ (es) â†’ nova (å¥³æ€§ï¼Œé€‚åˆæµªæ¼«è¯­è¨€)
    - ğŸ‡«ğŸ‡· æ³•è¯­ (fr) â†’ shimmer (æ¸©æš–æ¸…è„†)
    - ğŸ‡©ğŸ‡ª å¾·è¯­ (de) â†’ onyx (ç”·æ€§ï¼Œé€‚åˆå¾·è¯­ä¸¥è°¨æ„Ÿ)
    - ğŸ‡®ğŸ‡¹ æ„å¤§åˆ©è¯­ (it) â†’ nova (å¥³æ€§)
    - ğŸ‡µğŸ‡¹ è‘¡è„ç‰™è¯­ (pt) â†’ nova (å¥³æ€§)
    - ğŸ‡·ğŸ‡º ä¿„è¯­ (ru) â†’ echo (ç”·æ€§)
    - ğŸ‡¯ğŸ‡µ æ—¥è¯­ (ja) â†’ shimmer (æ¸…è„†)
    - ğŸ‡°ğŸ‡· éŸ©è¯­ (ko) â†’ shimmer (æ¸…è„†)
    - ğŸ‡¨ğŸ‡³ ä¸­æ–‡ (zh) â†’ nova (å¥³æ€§)
    - ğŸ‡¸ğŸ‡¦ é˜¿æ‹‰ä¼¯è¯­ (ar) â†’ fable (ç”·æ€§ï¼Œæ·±æ²‰)
    - ğŸ‡®ğŸ‡³ å°åœ°è¯­ (hi) â†’ nova (å¥³æ€§)
- `sync_method` (string, optional): Audio synchronization method
  - `"timing_analysis"` (default): Analyze animation timing for precise sync
  - `"narration_first"`: Generate narration then match video
  - `"subtitle_overlay"`: Add subtitles instead of audio sync

**Response (Success):**
```json
{
  "video_id": "550e8400-e29b-41d4-a716-446655440000",
  "video_url": "/videos/550e8400-e29b-41d4-a716-446655440000.mp4",
  "status": "success",
  "message": "Animation generated successfully"
}
```

**Response (Error):**
```json
{
  "detail": "Failed to generate animation: [error details]"
}
```

### `GET /videos/{video_id}.mp4` - Serve Video
Access generated video files directly.

**Example:** `http://localhost:8000/videos/550e8400-e29b-41d4-a716-446655440000.mp4`

## ğŸ’¡ Usage Examples

### Using curl
```bash
# Basic animation generation
curl -X POST "http://localhost:8000/generate" \
     -H "Content-Type: application/json" \
     -d '{
       "prompt": "Show how derivatives work in calculus",
       "resolution": "m"
     }'

# With audio narration
curl -X POST "http://localhost:8000/generate" \
     -H "Content-Type: application/json" \
     -d '{
       "prompt": "Explain the Pythagorean theorem",
       "resolution": "h",
       "include_audio": true,
       "voice": "nova",
       "language": "en"
     }'
```

### Using Python requests
```python
import requests
import time

def generate_animation(prompt, **kwargs):
    """Generate an educational animation."""
    url = "http://localhost:8000/generate"
    
    payload = {
        "prompt": prompt,
        "resolution": kwargs.get("resolution", "m"),
        "include_audio": kwargs.get("include_audio", True),
        "voice": kwargs.get("voice", "alloy"),
        "language": kwargs.get("language", "en"),
        "sync_method": kwargs.get("sync_method", "timing_analysis")
    }
    
    print(f"Generating animation for: {prompt}")
    response = requests.post(url, json=payload)
    
    if response.status_code == 200:
        result = response.json()
        video_url = f"http://localhost:8000{result['video_url']}"
        print(f"âœ… Animation ready: {video_url}")
        return result
    else:
        print(f"âŒ Error: {response.text}")
        return None

# Examples
animations = [
    {
        "prompt": "Explain the Pythagorean theorem with a visual proof",
        "resolution": "h",
        "voice": "nova"
    },
    {
        "prompt": "Show how photosynthesis works in plants",
        "include_audio": True,
        "language": "en"
    },
    {
        "prompt": "Demonstrate how bubble sort algorithm works",
        "resolution": "m",
        "sync_method": "timing_analysis"
    }
]

for animation in animations:
    result = generate_animation(**animation)
    if result:
        print(f"Video ID: {result['video_id']}")
    print("-" * 50)
```

### Using JavaScript/Node.js
```javascript
const axios = require('axios');

async function generateAnimation(prompt, options = {}) {
    try {
        const response = await axios.post('http://localhost:8000/generate', {
            prompt: prompt,
            resolution: options.resolution || 'm',
            include_audio: options.include_audio !== false,
            voice: options.voice || 'alloy',
            language: options.language || 'en',
            sync_method: options.sync_method || 'timing_analysis'
        });
        
        const result = response.data;
        const videoUrl = `http://localhost:8000${result.video_url}`;
        
        console.log(`âœ… Animation ready: ${videoUrl}`);
        return result;
    } catch (error) {
        console.error('âŒ Error:', error.response?.data || error.message);
        return null;
    }
}

// Example usage
generateAnimation("Explain how neural networks learn", {
    resolution: "h",
    voice: "nova",
    language: "en"
});
```

## ğŸ¯ Example Prompts

### Mathematics
- "Explain the Pythagorean theorem with a visual proof"
- "Show how calculus derivatives work with geometric interpretation"
- "Demonstrate the concept of limits in calculus"
- "Visualize how Fourier transforms work"
- "Explain complex numbers and their geometric representation"

### Science
- "Show how photosynthesis works in plants"
- "Explain DNA replication process step by step"
- "Demonstrate how planetary orbits work according to Kepler's laws"
- "Show how electromagnetic waves propagate"
- "Visualize how cellular mitosis occurs"

### Computer Science
- "Visualize how sorting algorithms work (bubble sort, merge sort)"
- "Explain how binary search trees function"
- "Show how neural networks learn through backpropagation"
- "Demonstrate how hash tables resolve collisions"
- "Visualize graph traversal algorithms (DFS, BFS)"

### Physics
- "Show how pendulum motion demonstrates simple harmonic motion"
- "Explain wave interference patterns"
- "Demonstrate conservation of momentum in collisions"
- "Visualize electric field lines around charges"
- "Show how lenses focus light rays"

## ğŸ—ï¸ Project Structure

```
manimations/
â”œâ”€â”€ app.py                 # Main FastAPI application
â”œâ”€â”€ main.py               # Entry point
â”œâ”€â”€ pyproject.toml        # Project configuration and dependencies
â”œâ”€â”€ uv.lock               # Dependency lock file
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ DEPLOY.md             # Ubuntu deployment guide
â”œâ”€â”€ .env.example          # Environment variables template
â”œâ”€â”€ .gitignore           # Git ignore rules
â”œâ”€â”€ models/               # Pydantic data models
â”‚   â””â”€â”€ schemas.py
â”œâ”€â”€ services/             # Core business logic
â”‚   â”œâ”€â”€ script_generator.py
â”‚   â”œâ”€â”€ audio_processor.py
â”‚   â””â”€â”€ video_processor.py
â”œâ”€â”€ utils/                # Configuration and helpers
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ helpers.py
â”œâ”€â”€ generated_videos/     # Served video files (created automatically)
â”œâ”€â”€ temp_scripts/        # Temporary generated scripts (created automatically)
â””â”€â”€ temp_output/         # Temporary Manim output (created automatically)
```

## âš ï¸ Error Handling

The API includes comprehensive error handling for:

- **Invalid prompts**: Empty or malformed requests
- **Script generation failures**: Claude AI service issues
- **Manim execution errors**: Script compilation or rendering problems
- **Audio generation errors**: TTS service failures
- **File system issues**: Disk space, permissions
- **Missing API keys**: Configuration problems
- **FFmpeg errors**: Audio/video processing failures

**Common Error Responses:**
```json
{
  "detail": "ANTHROPIC_API_KEY not set"
}
```
```json
{
  "detail": "Failed to generate animation: Manim execution failed"
}
```

## ğŸ”§ Configuration

### Environment Variables
- `ANTHROPIC_API_KEY`: Required for Claude AI script generation
- `OPENAI_API_KEY`: Required for TTS narration (optional if `include_audio=false`)
- `LOG_LEVEL`: Logging level (default: INFO)

### Performance Tuning
- **Video generation time**: 30 seconds to 5 minutes depending on complexity
- **Concurrent requests**: Supported, but resource-intensive
- **Disk space**: Each video ~1-50MB depending on resolution and duration
- **Memory usage**: 200-500MB per active generation

## ğŸš¨ Troubleshooting

### Common Issues

1. **FFmpeg not found**
   ```bash
   # macOS
   brew install ffmpeg
   
   # Ubuntu
   sudo apt install ffmpeg
   ```

2. **LaTeX compilation errors**
   ```bash
   # Install full LaTeX distribution
   # macOS: brew install --cask mactex
   # Ubuntu: sudo apt install texlive-full
   ```

3. **API key errors**
   ```bash
   export ANTHROPIC_API_KEY="your-key-here"
   export OPENAI_API_KEY="your-key-here"
   ```

4. **Port already in use**
   ```bash
   uv run uvicorn app:app --port 8001  # Use different port
   ```

5. **Memory issues with large animations**
   - Use lower resolution (`"l"` instead of `"h"`)
   - Disable audio generation (`"include_audio": false`)
   - Simplify the prompt

### Debugging
Enable debug logging:
```bash
export LOG_LEVEL=DEBUG
uv run python main.py
```

Check logs:
```bash
tail -f manimations.log
```

## ğŸ“ˆ Performance Notes

- **Generation Time**: 30s-5min based on complexity and resolution
- **Resolution Impact**: 4K takes ~4x longer than 720p
- **Audio Processing**: Adds 10-30s to generation time
- **Concurrent Limits**: Recommended max 3 simultaneous generations
- **Caching**: Generated videos are cached and served statically

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Add tests if applicable
5. Commit your changes (`git commit -m 'Add amazing feature'`)
6. Push to the branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- [Manim](https://www.manim.community/) - Mathematical Animation Engine
- [Anthropic Claude](https://www.anthropic.com/) - AI script generation
- [OpenAI](https://openai.com/) - Text-to-speech narration
- [FastAPI](https://fastapi.tiangolo.com/) - Web framework